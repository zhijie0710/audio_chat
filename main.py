# main.py
import sounddevice as sd
import numpy as np
import queue
from utils import load_hf_token
from llm import HuggingFaceLLM
from tts import TTS
from vad import SileroVAD
from asr import WhisperASR

# -----------------------------
# 1ï¸âƒ£ åŠ è½½ HF_TOKEN
# -----------------------------
hf_token = load_hf_token("/Users/zhijietang/Desktop/audio_chat/hf.env")

# -----------------------------
# 2ï¸âƒ£ åˆå§‹åŒ–æ¨¡å—
# -----------------------------
llm = HuggingFaceLLM(model_name="openai/gpt-oss-120b", temperature=0)
tts = TTS(rate=150)
vad = SileroVAD("vad.pt", sample_rate=16000)
asr = WhisperASR("tiny")

# -----------------------------
# 3ï¸âƒ£ éŸ³é¢‘é˜Ÿåˆ— & å‚æ•°
# -----------------------------
SAMPLE_RATE = 16000
CHANNELS = 1
BLOCK_SIZE = 512  # å¯¹åº” VAD.chunk_size
audio_queue = queue.Queue()

def audio_callback(indata, frames, time_info, status):
    """éº¦å…‹é£éŸ³é¢‘å›è°ƒï¼ŒæŠŠæ•°æ®æ”¾å…¥é˜Ÿåˆ—"""
    audio_queue.put(indata.copy())

# -----------------------------
# 4ï¸âƒ£ ä¸»å¾ªç¯
# -----------------------------
def main():
    buffer = np.zeros(0, dtype=np.float32)
    in_speech = False

    print("ğŸ™ï¸ å®æ—¶è¯­éŸ³åŠ©æ‰‹å¯åŠ¨ï¼Œè¯·è®²è¯... (è¯´ 'é€€å‡º' æˆ– 'å†è§' é€€å‡º)")


    with sd.InputStream(samplerate=SAMPLE_RATE, channels=CHANNELS,
                        blocksize=BLOCK_SIZE, callback=audio_callback):
        try:
            while True:
                try:
                    chunk = audio_queue.get(timeout=1)
                except queue.Empty:
                    continue

                chunk = chunk.flatten()
                buffer = np.concatenate((buffer, chunk))
                speech_flag = vad.is_speech(chunk)

                if speech_flag:
                    if not in_speech:
                        print("ğŸ—£ï¸ æ£€æµ‹åˆ°è¯´è¯")
                        tts.stop()  # æ‰“æ–­ TTS
                        in_speech = True
                else:
                    if in_speech:
                        print("â¹ï¸ è¯´è¯ç»“æŸï¼Œè¯†åˆ«ä¸­...")
                        text = asr.transcribe(buffer.copy())
                        print("ğŸ’¬ è¯†åˆ«:", text)

                        # æ£€æŸ¥é€€å‡ºæŒ‡ä»¤
                        if "é€€å‡º" in text or "å†è§" in text:
                            print("ğŸ‘‹ è¯­éŸ³åŠ©æ‰‹å·²é€€å‡º")
                            break

                        reply = llm.generate(text)
                        print("ğŸ¤– å›å¤:", reply)
                        tts.speak(reply)

                        buffer = np.zeros(0, dtype=np.float32)
                        in_speech = False
        except KeyboardInterrupt:
            print("\nğŸ‘‹ è¯­éŸ³åŠ©æ‰‹å·²é€šè¿‡ Ctrl+C é€€å‡º")

if __name__ == "__main__":
    main()